{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from scipy.io import arff\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "import threading\n",
    "import operator\n",
    "import collections\n",
    "from scipy.spatial import distance\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import manhattan_distances, euclidean_distances\n",
    "INPUT_DIR = \"./Datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeletClassifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def fetchDistanceMeasure(self,dist_fn):\n",
    "        # Map in the function of the distance metric\n",
    "        if dist_fn == 'euclidean':\n",
    "            return euclidean_distances\n",
    "        elif dist_fn == 'manhattan':\n",
    "            return manhattan_distances\n",
    "        elif dist_fn == 'cosine':\n",
    "            return distance.cosine\n",
    "        else:\n",
    "            return distance.euclidean\n",
    "   \n",
    "        \n",
    "    def __init__(self, min_len=20, max_len=20, n_threads=2, shapelet_count=10, dist_fn = 'euclidean'):\n",
    "        self.min_len = min_len\n",
    "        self.max_len = max_len\n",
    "        self.n_threads = n_threads\n",
    "        self.k = 1\n",
    "        self.dist_fn = self.fetchDistanceMeasure(dist_fn)\n",
    "        self.shapelet_count = shapelet_count\n",
    "        self.shapelet_dict = {}\n",
    "        self.shapelet_dict1 = {}\n",
    "        \n",
    "        \n",
    "#     def fit(self, X, y):\n",
    "#         self.time_series = X\n",
    "#         self.labels = y\n",
    "#         candidates = self.generate_candidates()\n",
    "#         split_candidates = np.array_split(candidates,self.n_threads)\n",
    "#         threads = [threading.Thread(target=self.find_best_shapelet_worker, args=[pd.DataFrame(split_candidate),]) for split_candidate in split_candidates]\n",
    "#         for thread in threads:\n",
    "#             thread.start()\n",
    "#         for thread in threads:\n",
    "#             thread.join()\n",
    "#         return self\n",
    "    def fit(self, X, y):\n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.time_series = X\n",
    "        self.classes = np.unique([label for label in y])\n",
    "        for _class in self.classes:\n",
    "            labels = []\n",
    "            print(\" Fetch Shapelets for \",_class)\n",
    "            for label in y:\n",
    "                if label == _class: labels.append(1)\n",
    "                else: labels.append(0) \n",
    "            self.labels = pd.Series(labels)\n",
    "            candidates = self.generate_candidates()\n",
    "            split_candidates = np.array_split(candidates,self.n_threads)\n",
    "            threads = [threading.Thread(target=self.find_best_shapelet_worker, args=[pd.DataFrame(split_candidate),]) for split_candidate in split_candidates]\n",
    "            for thread in threads:\n",
    "                thread.start()\n",
    "            for thread in threads:\n",
    "                thread.join()\n",
    "            self.shapelet_dict1[_class] = self.shapelet_dict\n",
    "            self.shapelet_dict = {}\n",
    "        return self\n",
    "    \n",
    "    def visualise_shapelet(self):\n",
    "        for _class in self.classes:\n",
    "            count = 0\n",
    "            print( \"FOR CLASS \",_class )\n",
    "            shapelet_dict = self.shapelet_dict1[_class]\n",
    "            for ig in sorted(shapelet_dict,reverse=True)[:self.shapelet_count]:\n",
    "                for shapelet in shapelet_dict[ig]:\n",
    "                    if count > self.shapelet_count:\n",
    "                        return\n",
    "                    print(\"Shapelet:\", shapelet)\n",
    "                    #print(\"Distance:\",shapelet_dict[shapelet][1])\n",
    "                    print(\"Information Gain:\",ig)\n",
    "                    plt.plot(shapelet[0])\n",
    "                    plt.show()\n",
    "                    count += 1\n",
    "\n",
    "    def predict(self, X, k=1, classifier=\"knn\"):\n",
    "        print(self.classes)\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self, ['shapelet_dict1'])\n",
    "\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "        # Output\n",
    "        y = list()\n",
    "        \n",
    "        # Map in the function of the distance metric\n",
    "        if classifier == 'dtree':\n",
    "            for x in X:\n",
    "                neighbours = {}\n",
    "                i=0\n",
    "                votes = {}\n",
    "                for _class in self.classes:\n",
    "                    shapelet_dict = self.shapelet_dict1[_class]\n",
    "                    for ig in sorted(shapelet_dict,reverse=True)[:self.shapelet_count]:\n",
    "                        for shapelet in shapelet_dict[ig]:\n",
    "                            dist,idx = self.subsequence_distance(x, shapelet[0])\n",
    "                            if (dist < shapelet[1]):\n",
    "                                y.append(_class)\n",
    "                            else:\n",
    "                                y.append(2.0)\n",
    "                            break       \n",
    "                        break\n",
    "                    break\n",
    "        elif classifier == 'dtree1':\n",
    "            for x in X:\n",
    "                neighbours = {}\n",
    "                i=0\n",
    "                votes = {}\n",
    "                for _class in self.classes:\n",
    "                    shapelet_dict = self.shapelet_dict1[_class]\n",
    "                    for ig in sorted(shapelet_dict,reverse=True)[:1]:\n",
    "                        for shapelet in shapelet_dict[ig]:\n",
    "                            dist,idx = self.subsequence_distance(x, shapelet[0])\n",
    "                            if (dist < shapelet[1]):\n",
    "                                y.append(_class)\n",
    "                                break\n",
    "                            else:\n",
    "                                continue\n",
    "                    break\n",
    "        else:\n",
    "            for x in X:\n",
    "                neighbours = {}\n",
    "                i=0\n",
    "                votes = {}\n",
    "                for _class in self.classes:\n",
    "                    shapelet_dict = self.shapelet_dict1[_class]\n",
    "                    for ig in sorted(shapelet_dict,reverse=True)[:self.shapelet_count]:\n",
    "                        for shapelet in shapelet_dict[ig]:\n",
    "                            dist,idx = self.subsequence_distance(x, shapelet[0])\n",
    "                            if dist not in neighbours:\n",
    "                                neighbours[dist] = _class\n",
    "                for neighbour in sorted(neighbours):\n",
    "                    if neighbours[neighbour] not in votes:\n",
    "                        votes[neighbours[neighbour]] = 1\n",
    "                    else:\n",
    "                        votes[neighbours[neighbour]] += 1\n",
    "                    i += 1\n",
    "                    if i > k:\n",
    "                        break\n",
    "                y.append(max(votes.items(), key=operator.itemgetter(1))[0])    \n",
    "        return y                \n",
    "    \n",
    "#     def search_label(self,time_serie, shapelet, split_point):\n",
    "#         dist,idx = self.subsequence_distance(time_serie,shapelet)\n",
    "#         if(idx < split_point):\n",
    "#             search_label(time_serie[:idx],shapelet,split_point)\n",
    "#         else:\n",
    "#             search_label(time_serie[idx:],shapelet,split_point)\n",
    "#     def predict(self, X):\n",
    "\n",
    "#         # Check is fit had been called\n",
    "#         check_is_fitted(self, ['shapelet_dict1'])\n",
    "\n",
    "#         # Input validation\n",
    "#         X = check_array(X)\n",
    "#         # Output\n",
    "#         y = list()\n",
    "#         for x in X:\n",
    "#             y_flag = False\n",
    "#             for _class in self.classes:\n",
    "#                 shapelet_dict = self.shapelet_dict1[_class]\n",
    "#                 for shapelet in sorted(shapelet_dict,reverse=True)[:self.shapelet_count]:\n",
    "#                     dist,idx = self.subsequence_distance(x, shapelet_dict[shapelet][0])\n",
    "#                       if(dist < shapelet_dict[shapelet][3]):\n",
    "# #                     if (dist <= shapelet_dict[shapelet][3]):\n",
    "# #                         y.append(_class)\n",
    "# #                         y_flag=True\n",
    "# #                         break\n",
    "# #                 if y_flag == True: \n",
    "# #                     break       \n",
    "#         return y\n",
    "    \n",
    "    def generate_candidates(self):\n",
    "        candidates, cand_len = [], self.max_len\n",
    "        while cand_len >= self.min_len:\n",
    "            for time_serie, label in zip(self.time_series,self.labels):\n",
    "                for k in range(len(time_serie)-cand_len+1):\n",
    "                    candidates.append((time_serie[k:k+cand_len], label))\n",
    "            cand_len -= 1\n",
    "        return pd.DataFrame(candidates)\n",
    "\n",
    "    def manhattan_distance(self, x, y, min_dist=float('inf')):\n",
    "        dist = np.sum(self.dist_fn([x,y]))\n",
    "        if dist >= min_dist: \n",
    "            return None\n",
    "        return dist\n",
    "\n",
    "    def subsequence_distance(self, time_serie, sub_seq):\n",
    "        if len(sub_seq) < len(time_serie):\n",
    "            min_dist, min_idx = float(\"inf\"), 0\n",
    "            for i in range(len(time_serie)-len(sub_seq)+1):\n",
    "                dist = self.manhattan_distance(sub_seq, time_serie[i:i+len(sub_seq)], min_dist)\n",
    "                if dist is not None and dist < min_dist: \n",
    "                    min_dist, min_idx = dist, i\n",
    "            return min_dist, min_idx\n",
    "        else:\n",
    "            return None, None\n",
    "\n",
    "    def calculate_entropy(self, probabilities):\n",
    "        return sum([-prob * np.log(prob)/np.log(2) if prob != 0 else 0 for prob in probabilities])\n",
    "\n",
    "    def calculate_dict_entropy(self, distances):\n",
    "        count = {}\n",
    "        for distance in distances:\n",
    "            if distance[1] in count:\n",
    "                count[distance[1]] += 1\n",
    "            else: \n",
    "                count[distance[1]] = 1\n",
    "        return self.calculate_entropy(np.divide(list(count.values()), float(sum(list(count.values())))))\n",
    "\n",
    "    def check_candidate(self,shapelet):\n",
    "        distances = {} \n",
    "        for time_serie,label in zip(self.time_series,self.labels):\n",
    "            dist, idx = self.subsequence_distance(time_serie, shapelet)\n",
    "            if dist is not None:\n",
    "                distances[dist] = [(time_serie, label)] if dist not in distances else distances[dist].append((time_serie, label))   \n",
    "        ordered_dict = collections.OrderedDict(sorted(distances.items()))\n",
    "        return self.find_best_split_dist(ordered_dict)\n",
    "\n",
    "    def find_best_split_dist(self, dist_dict):\n",
    "        distance_values = list(itertools.chain.from_iterable(list(dist_dict.values())))\n",
    "        prior_entropy = self.calculate_dict_entropy(distance_values)\n",
    "        best_distance, max_ig = 0, 0\n",
    "        best_split = 0\n",
    "        best_left, best_right = None, None\n",
    "        for split_distance in dist_dict:\n",
    "            split_left = []\n",
    "            split_right = []\n",
    "            for distance in dist_dict:\n",
    "                if distance <= split_distance: \n",
    "                    split_left.extend(dist_dict[distance])\n",
    "                else: \n",
    "                    split_right.extend(dist_dict[distance])\n",
    "            ig = prior_entropy - (float(len(split_left))/float(len(distance_values))*self.calculate_dict_entropy(split_left) + float(len(split_right))/float(len(distance_values)) * self.calculate_dict_entropy(split_right))\n",
    "            if ig > max_ig: \n",
    "                best_distance, max_ig, best_left, best_right = split_distance, ig, split_left, split_right\n",
    "        return max_ig, best_distance, best_left, best_right\n",
    "    \n",
    "    def find_best_shapelet_worker(self,candidates):\n",
    "        for candidate in candidates.values:\n",
    "            gain, dist, left, right = self.check_candidate(candidate[0])\n",
    "            if gain not in self.shapelet_dict:\n",
    "                self.shapelet_dict[gain]=[(candidate[0],dist)]\n",
    "            else:\n",
    "                self.shapelet_dict[gain].append((candidate[0],dist))\n",
    "#             print(\"Shapelet with gain Added: \",gain)\n",
    "#             print(\"Splited Data:\", [x[1] for x in left],\" & \",[x[1] for x in right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(INPUT_DIR+\"GunPoint/GunPoint_TRAIN.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "time_series, labels = df[df.columns[1:]].values,df[df.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fetch Shapelets for  1.0\n"
     ]
    }
   ],
   "source": [
    "sp = ShapeletClassifier(min_len=25,max_len=25,n_threads=1000)\n",
    "sp.fit(time_series,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR CLASS  1.0\n",
      "Shapelet: (array([-0.63818632, -0.63825875, -0.63834515, -0.63869741, -0.64304876,\n",
      "       -0.64376789, -0.64504991, -0.64711823, -0.64915334, -0.65124584,\n",
      "       -0.65729046, -0.66220082, -0.66123227, -0.66098661, -0.66156196,\n",
      "       -0.66225552, -0.66191228, -0.66274039, -0.66093438, -0.66344985,\n",
      "       -0.66219448, -0.6623359 , -0.66171176, -0.66139185, -0.66140829]), 0.29722466530009123)\n",
      "Information Gain: 0.9709505944546688\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-82392d841eec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualise_shapelet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-a86a8e9d51fc>\u001b[0m in \u001b[0;36mvisualise_shapelet\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m                     \u001b[0;31m#print(\"Distance:\",shapelet_dict[shapelet][1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Information Gain:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapelet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2809\u001b[0m     return gca().plot(\n\u001b[1;32m   2810\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2811\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36madd_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1893\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_line%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m         \"\"\"\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    943\u001b[0m         \"\"\"\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mrecache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m             \u001b[0myconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_yorig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_unmasked_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_to_unmasked_float_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sp.visualise_shapelet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 2.0, 2.0, 2.0]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = sp.predict(time_series,classifier=\"dtree\")\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted1 = sp.predict(time_series,classifier=\"dtree1\")\n",
    "predicted1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.0\n",
       "1    2.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    2.0\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predicted,labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k accuracy\n",
      "[1. 2.]\n",
      "0 : 0.48\n",
      "[1. 2.]\n",
      "1 : 0.48\n",
      "[1. 2.]\n",
      "2 : 0.48\n",
      "[1. 2.]\n",
      "3 : 0.48\n",
      "[1. 2.]\n",
      "4 : 0.48\n",
      "[1. 2.]\n",
      "5 : 0.48\n",
      "[1. 2.]\n",
      "6 : 0.48\n",
      "[1. 2.]\n",
      "7 : 0.48\n",
      "[1. 2.]\n",
      "8 : 0.48\n",
      "[1. 2.]\n",
      "9 : 0.48\n"
     ]
    }
   ],
   "source": [
    "print(\"k\",\"accuracy\")\n",
    "for k in range(10):\n",
    "    predicted = sp.predict(time_series,k+1)\n",
    "    acc = accuracy_score(predicted,labels)\n",
    "    print(k,\":\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates(data, max_len=3, min_len=3):\n",
    "    candidates, cand_len = [], max_len\n",
    "    while cand_len >= min_len:\n",
    "        time_series, labels = data.drop('target', axis=1).values, data['target']\n",
    "        for time_serie, label in zip(time_series,labels):\n",
    "            for k in range(len(time_serie)-cand_len+1):\n",
    "                candidates.append((time_serie[k:k+cand_len], label))\n",
    "        cand_len -= 1\n",
    "    return pd.DataFrame(candidates)\n",
    "\n",
    "def manhattan_distance(x, y, min_dist=float('inf')):\n",
    "    dist = np.sum(dist_manh([x,y],sum_over_features=False))\n",
    "    if dist >= min_dist: return None\n",
    "    return dist\n",
    "\n",
    "def subsequence_distance(time_series, sub_seq):\n",
    "    if len(sub_seq) < len(time_series):\n",
    "        min_dist, min_idx = float(\"inf\"), 0\n",
    "        for i in range(len(time_series)-len(sub_seq)+1):\n",
    "            dist = manhattan_distance(sub_seq, time_series[i:i+len(sub_seq)], min_dist)\n",
    "            if dist is not None and dist < min_dist: min_dist, min_idx = dist, i\n",
    "        return min_dist, min_idx\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def calculate_entropy(probabilities):\n",
    "    return sum([-prob * np.log(prob)/np.log(2) if prob != 0 else 0 for prob in probabilities])\n",
    "\n",
    "def calculate_dict_entropy(distances):\n",
    "    count = {}\n",
    "    for distance in distances:\n",
    "        if distance[1] in count:\n",
    "            count[distance[1]] += 1\n",
    "        else: \n",
    "            count[distance[1]] = 1\n",
    "    return calculate_entropy(np.divide(list(count.values()), float(sum(list(count.values())))))\n",
    "\n",
    "def check_candidate(time_series, shapelet):\n",
    "    distances = {} \n",
    "    data, labels = time_series.drop('target', axis=1).values, time_series['target']\n",
    "    for time_serie,label in zip(data,labels):\n",
    "        dist, idx = subsequence_distance(time_serie, shapelet)\n",
    "        if dist is not None:\n",
    "            distances[dist] = [(time_serie, label)] if dist not in distances else distances[dist].append((time_serie, label))        \n",
    "    return find_best_split_dist(distances)\n",
    "\n",
    "def find_best_split_dist(dist_dict):\n",
    "    distance_values = list(itertools.chain.from_iterable(list(dist_dict.values())))\n",
    "    prior_entropy = calculate_dict_entropy(distance_values)\n",
    "    best_distance, max_ig = 0, 0\n",
    "    best_left, best_right = None, None\n",
    "    for split_distance in dist_dict:\n",
    "        split_left = []\n",
    "        split_right = []\n",
    "        for distance in dist_dict:\n",
    "            if distance <= split_distance: \n",
    "                split_left.extend(dist_dict[distance])\n",
    "            else: \n",
    "                split_right.extend(dist_dict[distance])\n",
    "        ig = prior_entropy - (float(len(split_left))/float(len(distance_values))*calculate_dict_entropy(split_left) + float(len(split_right))/float(len(distance_values)) * calculate_dict_entropy(split_right))\n",
    "        if ig > max_ig: best_distance, max_ig, best_left, best_right = split_distance, ig, split_left, split_right\n",
    "    return max_ig, best_distance, best_left, best_right\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_shapelets_bf(data, max_len=10, min_len=10, plot=True, verbose=True):\n",
    "    candidates = generate_candidates(data, max_len, min_len)\n",
    "    bsf_gain, bsf_shapelet = 0, None\n",
    "    if verbose: candidates_length = len(candidates)\n",
    "    for idx, candidate in enumerate(candidates.values):\n",
    "        gain, dist, data_left, data_right = check_candidate(data, candidate[0])\n",
    "        if verbose: print(idx, '/', candidates_length, \":\", gain, dist)\n",
    "        if gain > bsf_gain:\n",
    "            bsf_gain, bsf_shapelet = gain, candidate[0]\n",
    "            if verbose:\n",
    "                print('Found new best shapelet with gain & dist:', bsf_gain, dist, [x[1] for x in data_left], \\\n",
    "                                                                                   [x[1] for x in data_right])\n",
    "            if plot:\n",
    "                plt.plot(bsf_shapelet)\n",
    "                plt.show()\n",
    "            plt.show()\n",
    "    return bsf_shapelet\n",
    "bsf_shapelet = find_shapelets_bf(df,verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidates = generate_candidates(df, 10, 10)\n",
    "# print(candidates.shape)\n",
    "# split_candidates = np.array_split(candidates,500)\n",
    "# split_candidates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from multiprocessing.pool import Pool\n",
    "# from multiprocessing import JoinableQueue as Queue\n",
    "# import os, sys\n",
    "\n",
    "# def find_best_shapelet_worker(data,candidates):\n",
    "#     bsf_gain, bsf_shapelet = 0, None\n",
    "#     for idx, candidate in enumerate(candidates.values):\n",
    "#         gain, dist, data_left, data_right = check_candidate(data, candidate[0])\n",
    "#         if gain > bsf_gain:\n",
    "#             bsf_gain, bsf_shapelet = gain, candidate[0]\n",
    "#     return bsf_shapelet,bsf_gain\n",
    "\n",
    "# def parallel_worker():\n",
    "#     while True:\n",
    "#         split_candidate = imageq.get()\n",
    "#         shapelet,gain = find_best_shapelet_worker(df, split_candidate) \n",
    "#         similarq.put( [shapelet, gain] )\n",
    "#         imageq.task_done()\n",
    "\n",
    "# similarq = Queue()\n",
    "# imageq = Queue()\n",
    "# candidates = generate_candidates(df, 10, 10)\n",
    "# print(\"done\")\n",
    "# split_candidates = np.array_split(candidates,500)\n",
    "# for split_candidate in split_candidates:\n",
    "#     imageq.put(pd.DataFrame(split_candidate))\n",
    "#     break\n",
    "\n",
    "# pool = Pool(5)\n",
    "# for i in range(5):\n",
    "#     pool.apply_async(parallel_worker)\n",
    "\n",
    "# imageq.join()\n",
    "\n",
    "# print(similarq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gain, best_shapelet = 0, None\n",
    "shapelet_dict = {}\n",
    "\n",
    "def find_best_shapelet_worker(data,candidates):\n",
    "    global best_gain, best_shapelet,shapelet_dict\n",
    "    for idx, candidate in enumerate(candidates.values):\n",
    "        gain, dist, data_left, data_right = check_candidate(data, candidate[0])\n",
    "        if gain not in shapelet_dict:\n",
    "            shapelet_dict[gain]=candidate[0]\n",
    "#         shapelet_dict = sorted(shapelet_dict)[:10]\n",
    "#         if\n",
    "#         if gain > best_gain:\n",
    "#             best_gain, best_shapelet = gain, candidate[0]\n",
    "            \n",
    "candidates = generate_candidates(df, 10, 10)\n",
    "print(\"done\")\n",
    "split_candidates = np.array_split(candidates,100)\n",
    "# print(split_candidates[0])\n",
    "threads = [threading.Thread(target=find_best_shapelet_worker, args=[df,pd.DataFrame(split_candidate),]) for split_candidate in split_candidates]\n",
    "# threads = [threading.Thread(target=find_best_shapelet_worker, args=[df,pd.DataFrame(split_candidates[0]),])]\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "print(shapelet_dict)\n",
    "# print(\"Shapelet:\",best_shapelet)\n",
    "# print(\"Information Gain:\",best_gain)\n",
    "# plt.plot(best_shapelet)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shapelet_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_shapelet_dict = sorted(shapelet_dict,reverse=True)[:10]\n",
    "for shapelet in sorted_shapelet_dict:\n",
    "    print(\"Shapelet:\",shapelet_dict[shapelet])\n",
    "    print(\"Information Gain:\",shapelet)\n",
    "    plt.plot(shapelet_dict[shapelet])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wrap_cand(data,max_len=3,min_len=3):\n",
    "    cand_len =  max_len\n",
    "    while cand_len >= min_len:\n",
    "        time_series, labels = data.drop('target', axis=1).values, data['target']\n",
    "        for time_serie, label in zip(time_series,labels):\n",
    "            for k in range(len(time_serie)-cand_len+1):\n",
    "                gen_cand.append((time_serie[k:k+cand_len], label))\n",
    "        cand_len -= 1\n",
    "thread_count = 10\n",
    "split_dfs = np.array_split(df, thread_count)\n",
    "gen_cand = []\n",
    "threads = [threading.Thread(target=wrap_cand, args=[pd.DataFrame(split_df),]) for split_df in split_dfs]\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "candidates = pd.DataFrame(gen_cand, columns=[\"shapelet\",\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for shaplet in candidates.shapelet:\n",
    "    dist = check_candidate(df,shaplet)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_dict_entropy(histogram_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
